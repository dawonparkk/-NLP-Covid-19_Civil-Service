{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i45d7E0L8bZ_"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **준비 사항**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "colab_type": "code",
    "id": "WkAHQrj2Vjbl",
    "outputId": "67ff8cff-ba1e-4112-8a8b-ff1bc3ddfa9f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (4.2.2)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (4.55.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from requests->transformers) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face의 트랜스포머 모델을 설치\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: h5py in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_bert/lib/python3.7/site-packages (from h5py->keras) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "75dIz2fNWG8F",
    "outputId": "62b45af1-a914-45d9-a5ab-3efdfc3f690c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_U3uMySBCIV"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "ImBtAkSyTW1r",
    "outputId": "bb0f4d70-8300-4122-c0ab-383e09fa41d1"
   },
   "outputs": [],
   "source": [
    "# 네이버 영화리뷰 감정분석 데이터 다운로드\n",
    "!git clone https://github.com/e9t/nsmc.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "nCKSDHcXTiKn",
    "outputId": "b70c3eba-8acf-4ec4-d7c9-1c93e11b64b3"
   },
   "outputs": [],
   "source": [
    "# 디렉토리의 파일 목록\n",
    "!ls nsmc -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "0LPEdb2tWfIU",
    "outputId": "ea4f105a-f41e-4f05-b9f0-2a2d8d0e981b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3)\n",
      "(50000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
    "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
    "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "tejY9ZhABYWl",
    "outputId": "896f7965-1e79-45f4-e983-5400907ec750"
   },
   "outputs": [],
   "source": [
    "# 훈련셋의 앞부분 출력\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgjMzosCDD35"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **전처리 - 훈련셋**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "2GoESQ0jbybJ",
    "outputId": "de3a4e29-1336-4a7f-d28c-48aaa7b16f6d"
   },
   "outputs": [],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = train['document']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "8KkJZvhccRUJ",
    "outputId": "f642184a-adaf-4be8-9999-457903a025f2"
   },
   "outputs": [],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "7hBblIVQcXJR",
    "outputId": "9fdef227-e4fe-4818-d940-afb1e95a2da2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = train['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125,
     "referenced_widgets": [
      "c33742ffe86a43baaf623f55386f6b8f",
      "24c7c4de897842daabfb4ab5bce59a5f",
      "283290212a5c48a087e649cb015d65e2",
      "47e09c7e47554a92939c6d6cdaff9f4d",
      "afb83fc933ed4efd946df40e7044ef75",
      "954cca3cf9f04ca8bbc7337f0301e04a",
      "9f5bd34100b14dd28cc3dd45eac9ee96",
      "c72b798f32c446b3b6cad9a12679b3ec"
     ]
    },
    "colab_type": "code",
    "id": "PwEplfDvcnZG",
    "outputId": "aa3c98e9-9ff0-4fb9-905c-87561dd77ddc"
   },
   "outputs": [],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "#tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "#print (sentences[0])\n",
    "#print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "VJ76KiP_dLn-",
    "outputId": "c23e248d-49ee-4a8e-e87b-bbf38e647d92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9519,   9074, 119005,    119,    119,   9708, 119235,\n",
       "         9715, 119230,  16439,  77884,  48549,   9284,  22333,  12692,\n",
       "          102,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "pKfL8SotdVaW",
    "outputId": "a82a6901-e6f0-4990-819b-3f962df89774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "colab_type": "code",
    "id": "1f5Vq3-7eNKH",
    "outputId": "0caabab2-c835-407d-a8e1-7baf01191730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   101,   9711,  11489,   9364,  41850,   9004,  32537,   9491,  35506,\n",
      "         17360,  48549,    119,    119,   9477,  26444,  12692,   9665,  21789,\n",
      "         11287,   9708, 119235,   9659,  22458, 119136,  12965,  48549,    119,\n",
      "           119,   9532,  22879,   9685,  16985,  14523,  48549,    119,    119,\n",
      "          9596, 118728,    119,    119,   9178, 106065, 118916,    119,    119,\n",
      "          8903,  11664,  11513,   9960,  14423,  25503, 118671,  48549,    119,\n",
      "           119,  21890,   9546,  37819,  22879,   9356,  14867,   9715, 119230,\n",
      "        118716,  48345,    119,   9663,  23321,  10954,   9638,  35506, 106320,\n",
      "         10739,  20173,   9359,  19105,  11102,  42428,  17196,  48549,    119,\n",
      "           119,    100,    117,   9947,  12945,   9532,  25503,   8932,  14423,\n",
      "         35506, 119050,  11903,  14867,  10003,  14863,  33188,  48345,    119,\n",
      "           102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([   101,   1871, 111754, 111754, 111754, 111754,    102,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n",
      "tensor(1)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 검증셋으로 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=2018, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=2018, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
    "\n",
    "print(train_inputs[0])\n",
    "print(train_labels[0])\n",
    "print(train_masks[0])\n",
    "print(validation_inputs[0])\n",
    "print(validation_labels[0])\n",
    "print(validation_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3vlyUJuVRo5"
   },
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkqUHx51dffp"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **전처리 - 테스트셋**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "xgrsNuArd4pj",
    "outputId": "317f5afc-9bad-4011-fce5-ec0cfe09312d"
   },
   "outputs": [],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = test['document']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "Gtz3QZt9d4pz",
    "outputId": "d7051edb-dd81-467a-c076-cff5dff3f291"
   },
   "outputs": [],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "li8oRajbd4p3",
    "outputId": "44e28db9-f88d-425b-a5ae-e7b207fe826e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = test['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "lvpQ49nEd4p6",
    "outputId": "8f6dc05a-2867-4844-bb31-fb9455b75573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 굳 ㅋ [SEP]\n",
      "['[CLS]', '굳', '[UNK]', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "HI9viuAvd4p_",
    "outputId": "234519e7-e4fe-481c-f2df-6d75b1f307ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 101, 8911,  100,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "v1NKmP0Fd4qD",
    "outputId": "253638c6-98ae-4d80-9a7a-127972f1a51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "RIkaYCGbd4qG",
    "outputId": "adf4595b-2c0f-4174-9fd2-73f29d05c97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 8911,  100,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor(1)\n",
      "tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 파이토치의 텐서로 변환\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "print(test_inputs[0])\n",
    "print(test_labels[0])\n",
    "print(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gwdYv1Ad4qK"
   },
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBvpU-Hfgcth"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **모델 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "heToD1ev0mOg",
    "outputId": "4e9bf7ad-35d9-4eb2-bd9e-5c19cd427c0a"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8c2f2159c4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "f6enIxvt1FB2",
    "outputId": "669c2993-7f63-4828-f6f2-d292f56efaa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ba3543867b3949b98a56b79766a7fe39",
      "7be0183b68c140f993db6df970e1b59e",
      "566d90a8747a41069a8a3e8809fcf1c7",
      "3706a29c1fd14cafb1527ba850d24dda",
      "3fa7bd6d2ebf435ca630fef08fe0e9a1",
      "b8a0fa47220f426d877ca05540befdfe",
      "b199891e7d7649d68480454645be2b8e",
      "dc40527794924690a1a50ee4a5683731",
      "d86637397e3f4c259bf6aff32a8ac917",
      "36bf4fd94daa477cb304f6e2f0e59585",
      "2b925cf0822f4bbfae8bd4b6d9ea3559",
      "50a457e2365d4d8f9b5cab009198b1c1",
      "931bdaf9d81f4c5c96be6a591f5d3a8a",
      "8fe822a741884e408b7b098bdd520391",
      "cc539678cb0f474385c29d29fec3aee4",
      "cc31bfb1dcfd4f0fba7dbcd02dab6671"
     ]
    },
    "colab_type": "code",
    "id": "MS2MXSiLg5zC",
    "outputId": "470e8fd8-02bd-453a-c5f2-e98282e815b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류를 위한 BERT 모델 생성\n",
    "model = torch.load('nsmc.pth')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIdfbLTuWmxk"
   },
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzCHV_ghj7DM"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **모델 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0-p6pPVXCRe"
   },
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJXISnJzCdLM"
   },
   "outputs": [],
   "source": [
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "muU2kS2GCh4y",
    "outputId": "bf35c728-34de-4347-bc68-d280840ad75f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  4,219.    Elapsed: 0:02:05.\n",
      "  Batch 1,000  of  4,219.    Elapsed: 0:04:10.\n",
      "  Batch 1,500  of  4,219.    Elapsed: 0:06:14.\n",
      "  Batch 2,000  of  4,219.    Elapsed: 0:08:19.\n",
      "  Batch 2,500  of  4,219.    Elapsed: 0:10:23.\n",
      "  Batch 3,000  of  4,219.    Elapsed: 0:12:28.\n",
      "  Batch 3,500  of  4,219.    Elapsed: 0:14:32.\n",
      "  Batch 4,000  of  4,219.    Elapsed: 0:16:37.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epcoh took: 0:17:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation took: 0:00:34\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  4,219.    Elapsed: 0:02:05.\n",
      "  Batch 1,000  of  4,219.    Elapsed: 0:04:09.\n",
      "  Batch 1,500  of  4,219.    Elapsed: 0:06:13.\n",
      "  Batch 2,000  of  4,219.    Elapsed: 0:08:18.\n",
      "  Batch 2,500  of  4,219.    Elapsed: 0:10:22.\n",
      "  Batch 3,000  of  4,219.    Elapsed: 0:12:25.\n",
      "  Batch 3,500  of  4,219.    Elapsed: 0:14:28.\n",
      "  Batch 4,000  of  4,219.    Elapsed: 0:16:32.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:17:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:34\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  4,219.    Elapsed: 0:02:04.\n",
      "  Batch 1,000  of  4,219.    Elapsed: 0:04:09.\n",
      "  Batch 1,500  of  4,219.    Elapsed: 0:06:13.\n",
      "  Batch 2,000  of  4,219.    Elapsed: 0:08:17.\n",
      "  Batch 2,500  of  4,219.    Elapsed: 0:10:21.\n",
      "  Batch 3,000  of  4,219.    Elapsed: 0:12:26.\n",
      "  Batch 3,500  of  4,219.    Elapsed: 0:14:30.\n",
      "  Batch 4,000  of  4,219.    Elapsed: 0:16:34.\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:17:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:34\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  4,219.    Elapsed: 0:02:04.\n",
      "  Batch 1,000  of  4,219.    Elapsed: 0:04:08.\n",
      "  Batch 1,500  of  4,219.    Elapsed: 0:06:11.\n",
      "  Batch 2,000  of  4,219.    Elapsed: 0:08:15.\n",
      "  Batch 2,500  of  4,219.    Elapsed: 0:10:20.\n",
      "  Batch 3,000  of  4,219.    Elapsed: 0:12:24.\n",
      "  Batch 3,500  of  4,219.    Elapsed: 0:14:28.\n",
      "  Batch 4,000  of  4,219.    Elapsed: 0:16:33.\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:17:28\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.87\n",
      "  Validation took: 0:00:34\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'nsmc.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BVbl4Zjatzn"
   },
   "source": [
    "\n",
    "# **테스트셋 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "c5KHb6RkbHdj",
    "outputId": "f3e8d193-c4ee-464c-f344-35ad52159e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  1,563.    Elapsed: 0:00:07.\n",
      "  Batch   200  of  1,563.    Elapsed: 0:00:14.\n",
      "  Batch   300  of  1,563.    Elapsed: 0:00:22.\n",
      "  Batch   400  of  1,563.    Elapsed: 0:00:29.\n",
      "  Batch   500  of  1,563.    Elapsed: 0:00:36.\n",
      "  Batch   600  of  1,563.    Elapsed: 0:00:43.\n",
      "  Batch   700  of  1,563.    Elapsed: 0:00:51.\n",
      "  Batch   800  of  1,563.    Elapsed: 0:00:58.\n",
      "  Batch   900  of  1,563.    Elapsed: 0:01:05.\n",
      "  Batch 1,000  of  1,563.    Elapsed: 0:01:12.\n",
      "  Batch 1,100  of  1,563.    Elapsed: 0:01:19.\n",
      "  Batch 1,200  of  1,563.    Elapsed: 0:01:27.\n",
      "  Batch 1,300  of  1,563.    Elapsed: 0:01:34.\n",
      "  Batch 1,400  of  1,563.    Elapsed: 0:01:41.\n",
      "  Batch 1,500  of  1,563.    Elapsed: 0:01:48.\n",
      "\n",
      "Accuracy: 0.87\n",
      "Test took: 0:01:53\n"
     ]
    }
   ],
   "source": [
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7SzL1IBe1Dm"
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# **새로운 문장 테스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-99331a9e6469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tb4v_VfEfGQB"
   },
   "outputs": [],
   "source": [
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts =  [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 150\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C12NL1Fvgv4E"
   },
   "outputs": [],
   "source": [
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.4699,  1.1918]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "[[-1.4698626  1.1918033]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['연기는 별로지만 재미 하나는 끝내줌!'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask as dd\n",
    "import pickle\n",
    "\n",
    "with open('dasan_CN.bin','rb') as f:\n",
    "    df_CN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CN = df_CN.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([\"[CLS]\"] + df_CN['CN'][0] + [\"[SEP]\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "SequenceClassifierOutput(loss=None, logits=tensor([[-1.1134,  0.6831],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-1.5279,  1.1883],\n",
      "        [-1.6718,  1.6528],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 0.1374, -0.7150],\n",
      "        [-0.1143, -0.0964],\n",
      "        [ 0.0713, -0.6025],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-1.6718,  1.6528],\n",
      "        [-1.5236,  1.1267],\n",
      "        [ 0.5568, -1.0379],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-0.4496, -0.2940],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 0.7498, -1.5091],\n",
      "        [-1.4145,  1.3889],\n",
      "        [-0.4949,  0.2490],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-0.6858,  0.5788],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 1.0165, -1.7116],\n",
      "        [ 0.9753, -1.6205],\n",
      "        [ 0.1024, -0.6255],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-1.8254,  1.7283],\n",
      "        [ 0.1024, -0.6255],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.8878,  0.7245],\n",
      "        [ 1.6528, -2.1795],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 0.5403, -1.1377],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-1.5456,  1.2504],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.6962,  0.0683],\n",
      "        [-1.1840,  1.0821],\n",
      "        [-0.8536,  0.2631],\n",
      "        [-0.0230, -0.5652],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.6118,  0.1120],\n",
      "        [ 0.1374, -0.7150],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.0228, -0.5284],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.3412,  0.0305],\n",
      "        [-1.8254,  1.7283],\n",
      "        [ 0.1024, -0.6255],\n",
      "        [-0.6377,  0.2984],\n",
      "        [-0.9229,  0.5680],\n",
      "        [-0.3391, -0.3827],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.0228, -0.5284],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.3412,  0.0305],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.8878,  0.7245],\n",
      "        [ 1.6528, -2.1795],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.5501, -0.1189],\n",
      "        [-0.2714, -0.5330],\n",
      "        [ 1.2728, -1.8788],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.0228, -0.5284],\n",
      "        [-0.4468, -0.1330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 1.5956, -2.2751],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.3412,  0.0305],\n",
      "        [-0.3563, -0.0521],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5329],\n",
      "        [ 0.7586, -1.3381],\n",
      "        [-0.0359, -0.2983],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 0.4628, -1.2976],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.8208,  0.4441],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.8081,  0.6204],\n",
      "        [-0.4468, -0.1330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-1.5279,  1.1883],\n",
      "        [-1.6718,  1.6528],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-0.1847, -0.2315],\n",
      "        [-0.5276,  0.4820],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.0228, -0.5284],\n",
      "        [-0.3977, -0.3889],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-1.3191,  0.8392],\n",
      "        [-0.4273, -0.1782],\n",
      "        [-1.8947,  1.6449],\n",
      "        [-0.2714, -0.5330],\n",
      "        [ 0.4750, -1.1657],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-1.4222,  1.1924],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.9431,  0.6893],\n",
      "        [-0.2343, -0.3491],\n",
      "        [ 0.1565, -0.6768],\n",
      "        [-1.0744,  0.7690],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-0.3248, -0.0611],\n",
      "        [ 1.4225, -2.0912],\n",
      "        [ 1.2263, -1.8462],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.8066,  0.0984],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.5337,  0.1307],\n",
      "        [-0.2714, -0.5330],\n",
      "        [-0.3563, -0.0521],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-1.6087,  1.3788],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 1.6014, -2.1494],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 0.1422, -0.6083],\n",
      "        [ 0.2323, -0.8627],\n",
      "        [ 0.9030, -1.4939],\n",
      "        [-0.3491, -0.1997],\n",
      "        [-0.0178, -0.5971],\n",
      "        [ 1.6014, -2.1494],\n",
      "        [-0.2715, -0.5330],\n",
      "        [-0.1776, -0.3753],\n",
      "        [-1.8254,  1.7283],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 1.1713, -1.8184],\n",
      "        [ 0.9030, -1.4939],\n",
      "        [-1.8254,  1.7283],\n",
      "        [-0.2715, -0.5330],\n",
      "        [ 1.1713, -1.8184],\n",
      "        [ 0.9030, -1.4939],\n",
      "        [ 1.1713, -1.8184],\n",
      "        [ 0.9030, -1.4939]], device='cuda:0'), hidden_states=None, attentions=None)\n",
      "55\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1 and 146 in dimension 1 at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-28a025e92fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_CN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1 and 146 in dimension 1 at /opt/conda/conda-bld/pytorch_1579022060824/work/aten/src/TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "tense = torch.Tensor([[0, 1]])#(df_CN.shape[0], 2)\n",
    "for i in range(5):\n",
    "    if i%1000 == 0 :\n",
    "        print(i)\n",
    "    logits = test_sentences(df_CN['CN'][i])\n",
    "    print(np.argmax(logits))\n",
    "    torch.stack([tense,F.softmax(torch.Tensor(logits))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0653, 0.9347])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[0.0653, 0.9347]]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002000\n",
      "2003000\n",
      "2004000\n",
      "2005000\n",
      "2006000\n",
      "2007000\n",
      "2008000\n",
      "2009000\n",
      "2010000\n",
      "2011000\n",
      "2012000\n",
      "2013000\n",
      "2014000\n",
      "2015000\n",
      "2016000\n",
      "2017000\n",
      "2018000\n",
      "2019000\n",
      "2020000\n",
      "2021000\n",
      "2022000\n",
      "2023000\n",
      "2024000\n",
      "2025000\n",
      "2026000\n",
      "2027000\n",
      "2028000\n",
      "2029000\n",
      "2030000\n",
      "2031000\n",
      "2032000\n",
      "2033000\n",
      "2034000\n",
      "2035000\n",
      "2036000\n",
      "2037000\n",
      "2038000\n",
      "2039000\n",
      "2040000\n",
      "2041000\n",
      "2042000\n",
      "2043000\n",
      "2044000\n",
      "2045000\n",
      "2046000\n",
      "2047000\n",
      "2048000\n",
      "2049000\n",
      "2050000\n",
      "2051000\n",
      "2052000\n",
      "2053000\n",
      "2054000\n",
      "2055000\n",
      "2056000\n",
      "2057000\n",
      "2058000\n",
      "2059000\n",
      "2060000\n",
      "2061000\n",
      "2062000\n",
      "2063000\n",
      "2064000\n",
      "2065000\n",
      "2066000\n",
      "2067000\n",
      "2068000\n",
      "2069000\n",
      "2070000\n",
      "2071000\n",
      "2072000\n",
      "2073000\n",
      "2074000\n",
      "2075000\n",
      "2076000\n",
      "2077000\n",
      "2078000\n",
      "2079000\n",
      "2080000\n",
      "2081000\n",
      "2082000\n",
      "2083000\n",
      "2084000\n",
      "2085000\n",
      "2086000\n",
      "2087000\n",
      "2088000\n",
      "2089000\n",
      "2090000\n",
      "2091000\n",
      "2092000\n",
      "2093000\n",
      "2094000\n",
      "2095000\n",
      "2096000\n",
      "2097000\n",
      "2098000\n",
      "2099000\n",
      "2100000\n",
      "2101000\n",
      "2102000\n",
      "2103000\n",
      "2104000\n",
      "2105000\n",
      "2106000\n",
      "2107000\n",
      "2108000\n",
      "2109000\n",
      "2110000\n",
      "2111000\n",
      "2112000\n",
      "2113000\n",
      "2114000\n",
      "2115000\n",
      "2116000\n",
      "2117000\n",
      "2118000\n",
      "2119000\n",
      "2120000\n",
      "2121000\n",
      "2122000\n",
      "2123000\n",
      "2124000\n",
      "2125000\n",
      "2126000\n",
      "2127000\n",
      "2128000\n",
      "2129000\n",
      "2130000\n",
      "2131000\n",
      "2132000\n",
      "2133000\n",
      "2134000\n",
      "2135000\n",
      "2136000\n",
      "2137000\n",
      "2138000\n",
      "2139000\n",
      "2140000\n",
      "2141000\n",
      "2142000\n",
      "2143000\n",
      "2144000\n",
      "2145000\n",
      "2146000\n",
      "2147000\n",
      "2148000\n",
      "2149000\n",
      "2150000\n",
      "2151000\n",
      "2152000\n",
      "2153000\n",
      "2154000\n",
      "2155000\n",
      "2156000\n",
      "2157000\n",
      "2158000\n",
      "2159000\n",
      "2160000\n",
      "2161000\n",
      "2162000\n",
      "2163000\n",
      "2164000\n",
      "2165000\n",
      "2166000\n",
      "2167000\n",
      "2168000\n",
      "2169000\n",
      "2170000\n",
      "2171000\n",
      "2172000\n",
      "2173000\n",
      "2174000\n",
      "2175000\n",
      "2176000\n",
      "2177000\n",
      "2178000\n",
      "2179000\n",
      "2180000\n",
      "2181000\n",
      "2182000\n",
      "2183000\n",
      "2184000\n",
      "2185000\n",
      "2186000\n",
      "2187000\n",
      "2188000\n",
      "2189000\n",
      "2190000\n",
      "2191000\n",
      "2192000\n",
      "2193000\n",
      "2194000\n",
      "2195000\n",
      "2196000\n",
      "2197000\n",
      "2198000\n",
      "2199000\n",
      "2200000\n",
      "2201000\n",
      "2202000\n",
      "2203000\n",
      "2204000\n",
      "2205000\n",
      "2206000\n",
      "2207000\n",
      "2208000\n",
      "2209000\n",
      "2210000\n",
      "2211000\n",
      "2212000\n",
      "2213000\n",
      "2214000\n",
      "2215000\n",
      "2216000\n",
      "2217000\n",
      "2218000\n",
      "2219000\n",
      "2220000\n",
      "2221000\n",
      "2222000\n",
      "2223000\n",
      "2224000\n",
      "2225000\n",
      "2226000\n",
      "2227000\n",
      "2228000\n",
      "2229000\n",
      "2230000\n",
      "2231000\n",
      "2232000\n",
      "2233000\n",
      "2234000\n",
      "2235000\n",
      "2236000\n",
      "2237000\n",
      "2238000\n",
      "2239000\n",
      "2240000\n",
      "2241000\n",
      "2242000\n",
      "2243000\n",
      "2244000\n",
      "2245000\n",
      "2246000\n",
      "2247000\n",
      "2248000\n",
      "2249000\n",
      "2250000\n",
      "2251000\n",
      "2252000\n",
      "2253000\n",
      "2254000\n",
      "2255000\n",
      "2256000\n",
      "2257000\n",
      "2258000\n",
      "2259000\n",
      "2260000\n",
      "2261000\n",
      "2262000\n",
      "2263000\n",
      "2264000\n",
      "2265000\n",
      "2266000\n",
      "2267000\n",
      "2268000\n",
      "2269000\n",
      "2270000\n",
      "2271000\n",
      "2272000\n",
      "2273000\n",
      "2274000\n",
      "2275000\n",
      "2276000\n",
      "2277000\n",
      "2278000\n",
      "2279000\n",
      "2280000\n",
      "2281000\n",
      "2282000\n",
      "2283000\n",
      "2284000\n",
      "2285000\n",
      "2286000\n",
      "2287000\n",
      "2288000\n",
      "2289000\n",
      "2290000\n",
      "2291000\n",
      "2292000\n",
      "2293000\n",
      "2294000\n",
      "2295000\n",
      "2296000\n",
      "2297000\n",
      "2298000\n",
      "2299000\n",
      "2300000\n",
      "2301000\n",
      "2302000\n",
      "2303000\n",
      "2304000\n",
      "2305000\n",
      "2306000\n",
      "2307000\n",
      "2308000\n",
      "2309000\n",
      "2310000\n",
      "2311000\n",
      "2312000\n",
      "2313000\n",
      "2314000\n",
      "2315000\n",
      "2316000\n",
      "2317000\n",
      "2318000\n",
      "2319000\n",
      "2320000\n",
      "2321000\n",
      "2322000\n",
      "2323000\n",
      "2324000\n",
      "2325000\n",
      "2326000\n",
      "2327000\n",
      "2328000\n",
      "2329000\n",
      "2330000\n",
      "2331000\n",
      "2332000\n",
      "2333000\n",
      "2334000\n",
      "2335000\n",
      "2336000\n",
      "2337000\n",
      "2338000\n",
      "2339000\n",
      "2340000\n",
      "2341000\n",
      "2342000\n",
      "2343000\n",
      "2344000\n",
      "2345000\n",
      "2346000\n",
      "2347000\n",
      "2348000\n",
      "2349000\n",
      "2350000\n",
      "2351000\n",
      "2352000\n",
      "2353000\n",
      "2354000\n",
      "2355000\n",
      "2356000\n",
      "2357000\n",
      "2358000\n",
      "2359000\n",
      "2360000\n",
      "2361000\n",
      "2362000\n",
      "2363000\n",
      "2364000\n",
      "2365000\n",
      "2366000\n",
      "2367000\n",
      "2368000\n",
      "2369000\n",
      "2370000\n",
      "2371000\n",
      "2372000\n",
      "2373000\n",
      "2374000\n",
      "2375000\n",
      "2376000\n",
      "2377000\n",
      "2378000\n",
      "2379000\n",
      "2380000\n",
      "2381000\n",
      "2382000\n",
      "2383000\n",
      "2384000\n",
      "2385000\n",
      "2386000\n",
      "2387000\n",
      "2388000\n",
      "2389000\n",
      "2390000\n",
      "2391000\n",
      "2392000\n",
      "2393000\n",
      "2394000\n",
      "2395000\n",
      "2396000\n",
      "2397000\n",
      "2398000\n",
      "2399000\n",
      "2400000\n",
      "2401000\n",
      "2402000\n",
      "2403000\n",
      "2404000\n",
      "2405000\n",
      "2406000\n",
      "2407000\n",
      "2408000\n",
      "2409000\n",
      "2410000\n",
      "2411000\n",
      "2412000\n",
      "2413000\n",
      "2414000\n",
      "2415000\n",
      "2416000\n",
      "2417000\n",
      "2418000\n",
      "2419000\n",
      "2420000\n",
      "2421000\n",
      "2422000\n",
      "2423000\n",
      "2424000\n",
      "2425000\n",
      "2426000\n",
      "2427000\n",
      "2428000\n",
      "2429000\n",
      "2430000\n",
      "2431000\n",
      "2432000\n",
      "2433000\n",
      "2434000\n",
      "2435000\n",
      "2436000\n",
      "2437000\n",
      "2438000\n",
      "2439000\n",
      "2440000\n",
      "2441000\n",
      "2442000\n",
      "2443000\n",
      "2444000\n",
      "2445000\n",
      "2446000\n",
      "2447000\n",
      "2448000\n",
      "2449000\n",
      "2450000\n",
      "2451000\n",
      "2452000\n",
      "2453000\n",
      "2454000\n",
      "2455000\n",
      "2456000\n",
      "2457000\n",
      "2458000\n",
      "2459000\n",
      "2460000\n",
      "2461000\n",
      "2462000\n",
      "2463000\n",
      "2464000\n",
      "2465000\n",
      "2466000\n",
      "2467000\n",
      "2468000\n",
      "2469000\n",
      "2470000\n",
      "2471000\n",
      "2472000\n",
      "2473000\n",
      "2474000\n",
      "2475000\n",
      "2476000\n",
      "2477000\n",
      "2478000\n",
      "2479000\n",
      "2480000\n",
      "2481000\n",
      "2482000\n",
      "2483000\n",
      "2484000\n",
      "2485000\n",
      "2486000\n",
      "2487000\n",
      "2488000\n",
      "2489000\n",
      "2490000\n",
      "2491000\n",
      "2492000\n",
      "2493000\n",
      "2494000\n",
      "2495000\n",
      "2496000\n",
      "2497000\n",
      "2498000\n",
      "2499000\n",
      "2500000\n",
      "2501000\n",
      "2502000\n",
      "2503000\n",
      "2504000\n",
      "2505000\n",
      "2506000\n",
      "2507000\n",
      "2508000\n",
      "2509000\n",
      "2510000\n",
      "2511000\n",
      "2512000\n",
      "2513000\n",
      "2514000\n",
      "2515000\n",
      "2516000\n",
      "2517000\n",
      "2518000\n",
      "2519000\n",
      "2520000\n",
      "2521000\n",
      "2522000\n",
      "2523000\n",
      "2524000\n",
      "2525000\n",
      "2526000\n",
      "2527000\n",
      "2528000\n",
      "2529000\n",
      "2530000\n",
      "2531000\n",
      "2532000\n",
      "2533000\n",
      "2534000\n",
      "2535000\n",
      "2536000\n",
      "2537000\n",
      "2538000\n",
      "2539000\n",
      "2540000\n",
      "2541000\n",
      "2542000\n",
      "2543000\n",
      "2544000\n",
      "2545000\n",
      "2546000\n",
      "2547000\n",
      "2548000\n",
      "2549000\n",
      "2550000\n",
      "2551000\n",
      "2552000\n",
      "2553000\n",
      "2554000\n",
      "2555000\n",
      "2556000\n",
      "2557000\n",
      "2558000\n",
      "2559000\n",
      "2560000\n",
      "2561000\n",
      "2562000\n",
      "2563000\n",
      "2564000\n",
      "2565000\n",
      "2566000\n",
      "2567000\n",
      "2568000\n",
      "2569000\n",
      "2570000\n",
      "2571000\n",
      "2572000\n",
      "2573000\n",
      "2574000\n",
      "2575000\n",
      "2576000\n",
      "2577000\n",
      "2578000\n",
      "2579000\n",
      "2580000\n",
      "2581000\n",
      "2582000\n",
      "2583000\n",
      "2584000\n",
      "2585000\n",
      "2586000\n",
      "2587000\n",
      "2588000\n",
      "2589000\n",
      "2590000\n",
      "2591000\n",
      "2592000\n",
      "2593000\n",
      "2594000\n",
      "2595000\n",
      "2596000\n",
      "2597000\n",
      "2598000\n",
      "2599000\n",
      "2600000\n",
      "2601000\n",
      "2602000\n",
      "2603000\n",
      "2604000\n",
      "2605000\n",
      "2606000\n",
      "2607000\n",
      "2608000\n",
      "2609000\n",
      "2610000\n",
      "2611000\n",
      "2612000\n",
      "2613000\n",
      "2614000\n",
      "2615000\n",
      "2616000\n",
      "2617000\n",
      "2618000\n",
      "2619000\n",
      "2620000\n",
      "2621000\n",
      "2622000\n",
      "2623000\n",
      "2624000\n",
      "2625000\n",
      "2626000\n",
      "2627000\n",
      "2628000\n",
      "2629000\n",
      "2630000\n",
      "2631000\n",
      "2632000\n",
      "2633000\n",
      "2634000\n",
      "2635000\n",
      "2636000\n",
      "2637000\n",
      "2638000\n",
      "2639000\n",
      "2640000\n",
      "2641000\n",
      "2642000\n",
      "2643000\n",
      "2644000\n",
      "2645000\n",
      "2646000\n",
      "2647000\n",
      "2648000\n",
      "2649000\n",
      "2650000\n",
      "2651000\n",
      "2652000\n",
      "2653000\n",
      "2654000\n",
      "2655000\n",
      "2656000\n",
      "2657000\n",
      "2658000\n",
      "2659000\n",
      "2660000\n",
      "2661000\n",
      "2662000\n",
      "2663000\n",
      "2664000\n",
      "2665000\n",
      "2666000\n",
      "2667000\n",
      "2668000\n",
      "2669000\n",
      "2670000\n",
      "2671000\n",
      "2672000\n",
      "2673000\n",
      "2674000\n",
      "2675000\n",
      "2676000\n",
      "2677000\n",
      "2678000\n",
      "2679000\n",
      "2680000\n",
      "2681000\n",
      "2682000\n",
      "2683000\n",
      "2684000\n",
      "2685000\n",
      "2686000\n",
      "2687000\n",
      "2688000\n",
      "2689000\n",
      "2690000\n",
      "2691000\n",
      "2692000\n",
      "2693000\n",
      "2694000\n",
      "2695000\n",
      "2696000\n",
      "2697000\n",
      "2698000\n",
      "2699000\n",
      "2700000\n",
      "2701000\n",
      "2702000\n",
      "2703000\n",
      "2704000\n",
      "2705000\n",
      "2706000\n",
      "2707000\n",
      "2708000\n",
      "2709000\n",
      "2710000\n",
      "2711000\n",
      "2712000\n",
      "2713000\n",
      "2714000\n",
      "2715000\n",
      "2716000\n",
      "2717000\n",
      "2718000\n",
      "2719000\n",
      "2720000\n",
      "2721000\n",
      "2722000\n",
      "2723000\n",
      "2724000\n",
      "2725000\n",
      "2726000\n",
      "2727000\n",
      "2728000\n",
      "2729000\n",
      "2730000\n",
      "2731000\n",
      "2732000\n",
      "2733000\n",
      "2734000\n",
      "2735000\n",
      "2736000\n",
      "2737000\n",
      "2738000\n",
      "2739000\n",
      "2740000\n",
      "2741000\n",
      "2742000\n",
      "2743000\n",
      "2744000\n",
      "2745000\n",
      "2746000\n",
      "2747000\n",
      "2748000\n",
      "2749000\n",
      "2750000\n",
      "2751000\n",
      "2752000\n",
      "2753000\n",
      "2754000\n",
      "2755000\n",
      "2756000\n",
      "2757000\n",
      "2758000\n",
      "2759000\n",
      "2760000\n",
      "2761000\n",
      "2762000\n",
      "2763000\n",
      "2764000\n",
      "2765000\n",
      "2766000\n",
      "2767000\n",
      "2768000\n",
      "2769000\n",
      "2770000\n",
      "2771000\n",
      "2772000\n",
      "2773000\n",
      "2774000\n",
      "2775000\n",
      "2776000\n",
      "2777000\n",
      "2778000\n",
      "2779000\n",
      "2780000\n",
      "2781000\n",
      "2782000\n",
      "2783000\n",
      "2784000\n",
      "2785000\n",
      "2786000\n",
      "2787000\n",
      "2788000\n",
      "2789000\n",
      "2790000\n",
      "2791000\n",
      "2792000\n",
      "2793000\n",
      "2794000\n",
      "2795000\n",
      "2796000\n",
      "2797000\n",
      "2798000\n",
      "2799000\n",
      "2800000\n",
      "2801000\n",
      "2802000\n",
      "2803000\n",
      "2804000\n",
      "2805000\n",
      "2806000\n",
      "2807000\n",
      "2808000\n",
      "2809000\n",
      "2810000\n",
      "2811000\n",
      "2812000\n",
      "2813000\n",
      "2814000\n",
      "2815000\n",
      "2816000\n",
      "2817000\n",
      "2818000\n",
      "2819000\n",
      "2820000\n",
      "2821000\n",
      "2822000\n",
      "2823000\n",
      "2824000\n",
      "2825000\n",
      "2826000\n",
      "2827000\n",
      "2828000\n",
      "2829000\n",
      "2830000\n",
      "2831000\n",
      "2832000\n",
      "2833000\n",
      "2834000\n",
      "2835000\n",
      "2836000\n",
      "2837000\n",
      "2838000\n",
      "2839000\n",
      "2840000\n",
      "2841000\n",
      "2842000\n",
      "2843000\n",
      "2844000\n",
      "2845000\n",
      "2846000\n",
      "2847000\n",
      "2848000\n",
      "2849000\n",
      "2850000\n",
      "2851000\n",
      "2852000\n",
      "2853000\n",
      "2854000\n",
      "2855000\n",
      "2856000\n",
      "2857000\n",
      "2858000\n",
      "2859000\n",
      "2860000\n",
      "2861000\n",
      "2862000\n",
      "2863000\n",
      "2864000\n",
      "2865000\n",
      "2866000\n",
      "2867000\n",
      "2868000\n",
      "2869000\n",
      "2870000\n",
      "2871000\n",
      "2872000\n",
      "2873000\n",
      "2874000\n",
      "2875000\n",
      "2876000\n",
      "2877000\n",
      "2878000\n",
      "2879000\n",
      "2880000\n",
      "2881000\n",
      "2882000\n",
      "2883000\n",
      "2884000\n",
      "2885000\n",
      "2886000\n",
      "2887000\n",
      "2888000\n",
      "2889000\n",
      "2890000\n",
      "2891000\n",
      "2892000\n",
      "2893000\n",
      "2894000\n",
      "2895000\n",
      "2896000\n",
      "2897000\n",
      "2898000\n",
      "2899000\n",
      "2900000\n",
      "2901000\n",
      "2902000\n",
      "2903000\n",
      "2904000\n",
      "2905000\n",
      "2906000\n",
      "2907000\n",
      "2908000\n",
      "2909000\n",
      "2910000\n",
      "2911000\n",
      "2912000\n",
      "2913000\n",
      "2914000\n",
      "2915000\n",
      "2916000\n",
      "2917000\n",
      "2918000\n",
      "2919000\n",
      "2920000\n",
      "2921000\n",
      "2922000\n",
      "2923000\n",
      "2924000\n",
      "2925000\n",
      "2926000\n",
      "2927000\n",
      "2928000\n",
      "2929000\n",
      "2930000\n",
      "2931000\n",
      "2932000\n",
      "2933000\n",
      "2934000\n",
      "2935000\n",
      "2936000\n",
      "2937000\n",
      "2938000\n",
      "2939000\n",
      "2940000\n",
      "2941000\n",
      "2942000\n",
      "2943000\n",
      "2944000\n",
      "2945000\n",
      "2946000\n",
      "2947000\n",
      "2948000\n",
      "2949000\n",
      "2950000\n",
      "2951000\n",
      "2952000\n",
      "2953000\n",
      "2954000\n",
      "2955000\n",
      "2956000\n",
      "2957000\n",
      "2958000\n",
      "2959000\n",
      "2960000\n",
      "2961000\n",
      "2962000\n",
      "2963000\n",
      "2964000\n",
      "2965000\n",
      "2966000\n",
      "2967000\n",
      "2968000\n",
      "2969000\n",
      "2970000\n",
      "2971000\n",
      "2972000\n",
      "2973000\n",
      "2974000\n",
      "2975000\n",
      "2976000\n",
      "2977000\n",
      "2978000\n",
      "2979000\n",
      "2980000\n",
      "2981000\n",
      "2982000\n",
      "2983000\n",
      "2984000\n",
      "2985000\n",
      "2986000\n",
      "2987000\n",
      "2988000\n",
      "2989000\n",
      "2990000\n",
      "2991000\n",
      "2992000\n",
      "2993000\n",
      "2994000\n",
      "2995000\n",
      "2996000\n",
      "2997000\n",
      "2998000\n",
      "2999000\n",
      "3000000\n",
      "3001000\n",
      "3002000\n",
      "3003000\n",
      "3004000\n",
      "3005000\n",
      "3006000\n",
      "3007000\n",
      "3008000\n",
      "3009000\n",
      "3010000\n",
      "3011000\n",
      "3012000\n",
      "3013000\n",
      "3014000\n",
      "3015000\n",
      "3016000\n",
      "3017000\n",
      "3018000\n",
      "3019000\n",
      "3020000\n",
      "3021000\n",
      "3022000\n",
      "3023000\n",
      "3024000\n",
      "3025000\n",
      "3026000\n",
      "3027000\n",
      "3028000\n",
      "3029000\n",
      "3030000\n",
      "3031000\n",
      "3032000\n",
      "3033000\n",
      "3034000\n",
      "3035000\n",
      "3036000\n",
      "3037000\n",
      "3038000\n",
      "3039000\n",
      "3040000\n",
      "3041000\n",
      "3042000\n",
      "3043000\n",
      "3044000\n",
      "3045000\n",
      "3046000\n",
      "3047000\n",
      "3048000\n",
      "3049000\n",
      "3050000\n",
      "3051000\n",
      "3052000\n",
      "3053000\n",
      "3054000\n",
      "3055000\n",
      "3056000\n",
      "3057000\n",
      "3058000\n",
      "3059000\n",
      "3060000\n",
      "3061000\n",
      "3062000\n",
      "3063000\n",
      "3064000\n",
      "3065000\n",
      "3066000\n",
      "3067000\n",
      "3068000\n",
      "3069000\n",
      "3070000\n",
      "3071000\n",
      "3072000\n",
      "3073000\n",
      "3074000\n",
      "3075000\n",
      "3076000\n",
      "3077000\n",
      "3078000\n",
      "3079000\n",
      "3080000\n",
      "3081000\n",
      "3082000\n",
      "3083000\n",
      "3084000\n",
      "3085000\n",
      "3086000\n",
      "3087000\n",
      "3088000\n",
      "3089000\n",
      "3090000\n",
      "3091000\n",
      "3092000\n",
      "3093000\n",
      "3094000\n",
      "3095000\n",
      "3096000\n",
      "3097000\n",
      "3098000\n",
      "3099000\n",
      "3100000\n",
      "3101000\n",
      "3102000\n",
      "3103000\n",
      "3104000\n",
      "3105000\n",
      "3106000\n",
      "3107000\n",
      "3108000\n",
      "3109000\n",
      "3110000\n",
      "3111000\n",
      "3112000\n",
      "3113000\n",
      "3114000\n",
      "3115000\n",
      "3116000\n",
      "3117000\n",
      "3118000\n",
      "3119000\n",
      "3120000\n",
      "3121000\n",
      "3122000\n",
      "3123000\n",
      "3124000\n",
      "3125000\n",
      "3126000\n",
      "3127000\n",
      "3128000\n",
      "3129000\n",
      "3130000\n",
      "3131000\n",
      "3132000\n",
      "3133000\n",
      "3134000\n",
      "3135000\n",
      "3136000\n",
      "3137000\n",
      "3138000\n",
      "3139000\n",
      "3140000\n",
      "3141000\n",
      "3142000\n",
      "3143000\n",
      "3144000\n",
      "3145000\n",
      "3146000\n",
      "3147000\n",
      "3148000\n",
      "3149000\n",
      "3150000\n",
      "3151000\n",
      "3152000\n",
      "3153000\n",
      "3154000\n",
      "3155000\n",
      "3156000\n",
      "3157000\n",
      "3158000\n",
      "3159000\n",
      "3160000\n",
      "3161000\n",
      "3162000\n",
      "3163000\n",
      "3164000\n",
      "3165000\n",
      "3166000\n",
      "3167000\n",
      "3168000\n",
      "3169000\n",
      "3170000\n",
      "3171000\n",
      "3172000\n",
      "3173000\n",
      "3174000\n",
      "3175000\n",
      "3176000\n",
      "3177000\n",
      "3178000\n",
      "3179000\n",
      "3180000\n",
      "3181000\n",
      "3182000\n",
      "3183000\n",
      "3184000\n",
      "3185000\n",
      "3186000\n",
      "3187000\n",
      "3188000\n",
      "3189000\n",
      "3190000\n",
      "3191000\n",
      "3192000\n",
      "3193000\n",
      "3194000\n",
      "3195000\n",
      "3196000\n",
      "3197000\n",
      "3198000\n",
      "3199000\n",
      "3200000\n",
      "3201000\n",
      "3202000\n",
      "3203000\n",
      "3204000\n",
      "3205000\n",
      "3206000\n",
      "3207000\n",
      "3208000\n",
      "3209000\n",
      "3210000\n",
      "3211000\n",
      "3212000\n",
      "3213000\n",
      "3214000\n",
      "3215000\n",
      "3216000\n",
      "3217000\n",
      "3218000\n",
      "3219000\n",
      "3220000\n",
      "3221000\n",
      "3222000\n",
      "3223000\n",
      "3224000\n",
      "3225000\n",
      "3226000\n",
      "3227000\n",
      "3228000\n",
      "3229000\n",
      "3230000\n",
      "3231000\n",
      "3232000\n",
      "3233000\n",
      "3234000\n",
      "3235000\n",
      "3236000\n",
      "3237000\n",
      "3238000\n",
      "3239000\n",
      "3240000\n",
      "3241000\n",
      "3242000\n",
      "3243000\n",
      "3244000\n",
      "3245000\n",
      "3246000\n",
      "3247000\n",
      "3248000\n",
      "3249000\n",
      "3250000\n",
      "3251000\n",
      "3252000\n",
      "3253000\n",
      "3254000\n",
      "3255000\n",
      "3256000\n",
      "3257000\n",
      "3258000\n",
      "3259000\n",
      "3260000\n",
      "3261000\n",
      "3262000\n",
      "3263000\n",
      "3264000\n",
      "3265000\n",
      "3266000\n",
      "3267000\n",
      "3268000\n",
      "3269000\n",
      "3270000\n",
      "3271000\n",
      "3272000\n",
      "3273000\n",
      "3274000\n",
      "3275000\n",
      "3276000\n",
      "3277000\n",
      "3278000\n",
      "3279000\n",
      "3280000\n",
      "3281000\n",
      "3282000\n",
      "3283000\n",
      "3284000\n",
      "3285000\n",
      "3286000\n",
      "3287000\n",
      "3288000\n",
      "3289000\n",
      "3290000\n",
      "3291000\n",
      "3292000\n",
      "3293000\n",
      "3294000\n",
      "3295000\n",
      "3296000\n",
      "3297000\n",
      "3298000\n",
      "3299000\n",
      "3300000\n",
      "3301000\n",
      "3302000\n",
      "3303000\n",
      "3304000\n",
      "3305000\n",
      "3306000\n",
      "3307000\n",
      "3308000\n",
      "3309000\n",
      "3310000\n",
      "3311000\n",
      "3312000\n",
      "3313000\n",
      "3314000\n",
      "3315000\n",
      "3316000\n",
      "3317000\n",
      "3318000\n",
      "3319000\n",
      "3320000\n",
      "3321000\n",
      "3322000\n",
      "3323000\n",
      "3324000\n",
      "3325000\n",
      "3326000\n",
      "3327000\n",
      "3328000\n",
      "3329000\n",
      "3330000\n",
      "3331000\n",
      "3332000\n",
      "3333000\n",
      "3334000\n",
      "3335000\n",
      "3336000\n",
      "3337000\n",
      "3338000\n",
      "3339000\n",
      "3340000\n",
      "3341000\n",
      "3342000\n",
      "3343000\n",
      "3344000\n",
      "3345000\n",
      "3346000\n",
      "3347000\n",
      "3348000\n",
      "3349000\n",
      "3350000\n",
      "3351000\n",
      "3352000\n",
      "3353000\n",
      "3354000\n",
      "3355000\n",
      "3356000\n",
      "3357000\n",
      "3358000\n",
      "3359000\n",
      "3360000\n",
      "3361000\n",
      "3362000\n",
      "3363000\n",
      "3364000\n",
      "3365000\n",
      "3366000\n",
      "3367000\n",
      "3368000\n",
      "3369000\n",
      "3370000\n",
      "3371000\n",
      "3372000\n",
      "3373000\n",
      "3374000\n",
      "3375000\n",
      "3376000\n",
      "3377000\n",
      "3378000\n",
      "3379000\n",
      "3380000\n",
      "3381000\n",
      "3382000\n",
      "3383000\n",
      "3384000\n",
      "3385000\n",
      "3386000\n",
      "3387000\n",
      "3388000\n",
      "3389000\n",
      "3390000\n",
      "3391000\n",
      "3392000\n",
      "3393000\n",
      "3394000\n",
      "3395000\n",
      "3396000\n",
      "3397000\n",
      "3398000\n",
      "3399000\n",
      "3400000\n",
      "3401000\n",
      "3402000\n",
      "3403000\n",
      "3404000\n",
      "3405000\n",
      "3406000\n",
      "3407000\n",
      "3408000\n",
      "3409000\n",
      "3410000\n",
      "3411000\n",
      "3412000\n",
      "3413000\n",
      "3414000\n",
      "3415000\n",
      "3416000\n",
      "3417000\n",
      "3418000\n",
      "3419000\n",
      "3420000\n",
      "3421000\n",
      "3422000\n",
      "3423000\n",
      "3424000\n",
      "3425000\n",
      "3426000\n",
      "3427000\n",
      "3428000\n",
      "3429000\n",
      "3430000\n",
      "3431000\n",
      "3432000\n",
      "3433000\n",
      "3434000\n",
      "3435000\n",
      "3436000\n",
      "3437000\n",
      "3438000\n",
      "3439000\n",
      "3440000\n",
      "3441000\n",
      "3442000\n",
      "3443000\n",
      "3444000\n",
      "3445000\n",
      "3446000\n",
      "3447000\n",
      "3448000\n",
      "3449000\n",
      "3450000\n",
      "3451000\n",
      "3452000\n",
      "3453000\n",
      "3454000\n",
      "3455000\n",
      "3456000\n",
      "3457000\n",
      "3458000\n",
      "3459000\n",
      "3460000\n",
      "3461000\n",
      "3462000\n",
      "3463000\n",
      "3464000\n",
      "3465000\n",
      "3466000\n",
      "3467000\n",
      "3468000\n",
      "3469000\n",
      "3470000\n",
      "3471000\n",
      "3472000\n",
      "3473000\n",
      "3474000\n",
      "3475000\n",
      "3476000\n",
      "3477000\n",
      "3478000\n",
      "3479000\n",
      "3480000\n",
      "3481000\n",
      "3482000\n",
      "3483000\n",
      "3484000\n",
      "3485000\n",
      "3486000\n",
      "3487000\n",
      "3488000\n",
      "3489000\n",
      "3490000\n",
      "3491000\n",
      "3492000\n",
      "3493000\n",
      "3494000\n",
      "3495000\n",
      "3496000\n",
      "3497000\n",
      "3498000\n",
      "3499000\n",
      "3500000\n",
      "3501000\n",
      "3502000\n",
      "3503000\n",
      "3504000\n",
      "3505000\n",
      "3506000\n",
      "3507000\n",
      "3508000\n",
      "3509000\n",
      "3510000\n",
      "3511000\n",
      "3512000\n",
      "3513000\n",
      "3514000\n",
      "3515000\n",
      "3516000\n",
      "3517000\n",
      "3518000\n",
      "3519000\n",
      "3520000\n",
      "3521000\n",
      "3522000\n",
      "3523000\n",
      "3524000\n",
      "3525000\n",
      "3526000\n",
      "3527000\n",
      "3528000\n",
      "3529000\n",
      "3530000\n",
      "3531000\n",
      "3532000\n",
      "3533000\n",
      "3534000\n",
      "3535000\n",
      "3536000\n",
      "3537000\n",
      "3538000\n",
      "3539000\n",
      "3540000\n",
      "3541000\n",
      "3542000\n",
      "3543000\n",
      "3544000\n",
      "3545000\n",
      "3546000\n",
      "3547000\n",
      "3548000\n",
      "3549000\n",
      "3550000\n",
      "3551000\n",
      "3552000\n",
      "3553000\n",
      "3554000\n",
      "3555000\n",
      "3556000\n",
      "3557000\n",
      "3558000\n",
      "3559000\n",
      "3560000\n",
      "3561000\n",
      "3562000\n",
      "3563000\n",
      "3564000\n",
      "3565000\n",
      "3566000\n",
      "3567000\n",
      "3568000\n",
      "3569000\n",
      "3570000\n",
      "3571000\n",
      "3572000\n",
      "3573000\n",
      "3574000\n",
      "3575000\n",
      "3576000\n",
      "3577000\n",
      "3578000\n",
      "3579000\n",
      "3580000\n",
      "3581000\n",
      "3582000\n",
      "3583000\n",
      "3584000\n",
      "3585000\n",
      "3586000\n",
      "3587000\n",
      "3588000\n",
      "3589000\n",
      "3590000\n",
      "3591000\n",
      "3592000\n",
      "3593000\n",
      "3594000\n",
      "3595000\n",
      "3596000\n",
      "3597000\n",
      "3598000\n",
      "3599000\n",
      "3600000\n",
      "3601000\n",
      "3602000\n",
      "3603000\n",
      "3604000\n",
      "3605000\n",
      "3606000\n",
      "3607000\n",
      "3608000\n",
      "3609000\n",
      "3610000\n",
      "3611000\n",
      "3612000\n",
      "3613000\n",
      "3614000\n",
      "3615000\n",
      "3616000\n",
      "3617000\n",
      "3618000\n",
      "3619000\n",
      "3620000\n",
      "3621000\n",
      "3622000\n",
      "3623000\n",
      "3624000\n",
      "3625000\n",
      "3626000\n",
      "3627000\n",
      "3628000\n",
      "3629000\n",
      "3630000\n",
      "3631000\n",
      "3632000\n",
      "3633000\n",
      "3634000\n",
      "3635000\n",
      "3636000\n",
      "3637000\n",
      "3638000\n",
      "3639000\n",
      "3640000\n",
      "3641000\n",
      "3642000\n",
      "3643000\n",
      "3644000\n",
      "3645000\n",
      "3646000\n",
      "3647000\n",
      "3648000\n",
      "3649000\n",
      "3650000\n",
      "3651000\n",
      "3652000\n",
      "3653000\n",
      "3654000\n",
      "3655000\n",
      "3656000\n",
      "3657000\n",
      "3658000\n",
      "3659000\n",
      "3660000\n",
      "3661000\n",
      "3662000\n",
      "3663000\n",
      "3664000\n",
      "3665000\n",
      "3666000\n",
      "3667000\n",
      "3668000\n",
      "3669000\n",
      "3670000\n",
      "3671000\n",
      "3672000\n",
      "3673000\n",
      "3674000\n",
      "3675000\n",
      "3676000\n",
      "3677000\n",
      "3678000\n",
      "3679000\n",
      "3680000\n",
      "3681000\n",
      "3682000\n",
      "3683000\n",
      "3684000\n",
      "3685000\n",
      "3686000\n",
      "3687000\n",
      "3688000\n",
      "3689000\n",
      "3690000\n",
      "3691000\n",
      "3692000\n",
      "3693000\n",
      "3694000\n",
      "3695000\n",
      "3696000\n",
      "3697000\n",
      "3698000\n",
      "3699000\n",
      "3700000\n",
      "3701000\n",
      "3702000\n",
      "3703000\n",
      "3704000\n",
      "3705000\n",
      "3706000\n",
      "3707000\n",
      "3708000\n",
      "3709000\n",
      "3710000\n",
      "3711000\n",
      "3712000\n",
      "3713000\n",
      "3714000\n",
      "3715000\n",
      "3716000\n",
      "3717000\n",
      "3718000\n",
      "3719000\n",
      "3720000\n",
      "3721000\n",
      "3722000\n",
      "3723000\n",
      "3724000\n",
      "3725000\n",
      "3726000\n",
      "3727000\n",
      "3728000\n",
      "3729000\n",
      "3730000\n",
      "3731000\n",
      "3732000\n",
      "3733000\n",
      "3734000\n",
      "3735000\n",
      "3736000\n",
      "3737000\n",
      "3738000\n",
      "3739000\n",
      "3740000\n",
      "3741000\n",
      "3742000\n",
      "3743000\n",
      "3744000\n",
      "3745000\n",
      "3746000\n",
      "3747000\n",
      "3748000\n",
      "3749000\n",
      "3750000\n",
      "3751000\n",
      "3752000\n",
      "3753000\n",
      "3754000\n",
      "3755000\n",
      "3756000\n",
      "3757000\n",
      "3758000\n",
      "3759000\n",
      "3760000\n",
      "3761000\n",
      "3762000\n",
      "3763000\n",
      "3764000\n",
      "3765000\n",
      "3766000\n",
      "3767000\n",
      "3768000\n",
      "3769000\n",
      "3770000\n",
      "3771000\n",
      "3772000\n",
      "3773000\n",
      "3774000\n",
      "3775000\n",
      "3776000\n",
      "3777000\n",
      "3778000\n",
      "3779000\n",
      "3780000\n",
      "3781000\n",
      "3782000\n",
      "3783000\n",
      "3784000\n",
      "3785000\n",
      "3786000\n",
      "3787000\n",
      "3788000\n",
      "3789000\n",
      "3790000\n",
      "3791000\n",
      "3792000\n",
      "3793000\n",
      "3794000\n",
      "3795000\n",
      "3796000\n",
      "3797000\n",
      "3798000\n",
      "3799000\n",
      "3800000\n",
      "3801000\n",
      "3802000\n",
      "3803000\n",
      "3804000\n",
      "3805000\n",
      "3806000\n",
      "3807000\n",
      "3808000\n",
      "3809000\n",
      "3810000\n",
      "3811000\n",
      "3812000\n",
      "3813000\n",
      "3814000\n",
      "3815000\n",
      "3816000\n",
      "3817000\n",
      "3818000\n",
      "3819000\n",
      "3820000\n",
      "3821000\n",
      "3822000\n",
      "3823000\n",
      "3824000\n",
      "3825000\n",
      "3826000\n",
      "3827000\n",
      "3828000\n",
      "3829000\n",
      "3830000\n",
      "3831000\n",
      "3832000\n",
      "3833000\n",
      "3834000\n",
      "3835000\n",
      "3836000\n",
      "3837000\n",
      "3838000\n",
      "3839000\n",
      "3840000\n",
      "3841000\n",
      "3842000\n",
      "3843000\n",
      "3844000\n",
      "3845000\n",
      "3846000\n",
      "3847000\n",
      "3848000\n",
      "3849000\n",
      "3850000\n",
      "3851000\n",
      "3852000\n",
      "3853000\n",
      "3854000\n",
      "3855000\n",
      "3856000\n",
      "3857000\n",
      "3858000\n",
      "3859000\n",
      "3860000\n",
      "3861000\n",
      "3862000\n",
      "3863000\n",
      "3864000\n",
      "3865000\n",
      "3866000\n",
      "3867000\n",
      "3868000\n",
      "3869000\n",
      "3870000\n",
      "3871000\n",
      "3872000\n",
      "3873000\n",
      "3874000\n",
      "3875000\n",
      "3876000\n",
      "3877000\n",
      "3878000\n",
      "3879000\n",
      "3880000\n",
      "3881000\n",
      "3882000\n",
      "3883000\n",
      "3884000\n",
      "3885000\n",
      "3886000\n",
      "3887000\n",
      "3888000\n",
      "3889000\n",
      "3890000\n",
      "3891000\n",
      "3892000\n",
      "3893000\n",
      "3894000\n",
      "3895000\n",
      "3896000\n",
      "3897000\n",
      "3898000\n",
      "3899000\n",
      "3900000\n",
      "3901000\n",
      "3902000\n",
      "3903000\n",
      "3904000\n",
      "3905000\n",
      "3906000\n",
      "3907000\n",
      "3908000\n",
      "3909000\n",
      "3910000\n",
      "3911000\n",
      "3912000\n",
      "3913000\n",
      "3914000\n",
      "3915000\n",
      "3916000\n",
      "3917000\n",
      "3918000\n",
      "3919000\n",
      "3920000\n",
      "3921000\n",
      "3922000\n",
      "3923000\n",
      "3924000\n",
      "3925000\n",
      "3926000\n",
      "3927000\n",
      "3928000\n",
      "3929000\n",
      "3930000\n",
      "3931000\n",
      "3932000\n",
      "3933000\n",
      "3934000\n",
      "3935000\n",
      "3936000\n",
      "3937000\n",
      "3938000\n",
      "3939000\n",
      "3940000\n",
      "3941000\n",
      "3942000\n",
      "3943000\n",
      "3944000\n",
      "3945000\n",
      "3946000\n",
      "3947000\n",
      "3948000\n",
      "3949000\n",
      "3950000\n",
      "3951000\n",
      "3952000\n",
      "3953000\n",
      "3954000\n",
      "3955000\n",
      "3956000\n",
      "3957000\n",
      "3958000\n",
      "3959000\n",
      "3960000\n",
      "3961000\n",
      "3962000\n",
      "3963000\n",
      "3964000\n",
      "3965000\n",
      "3966000\n",
      "3967000\n",
      "3968000\n",
      "3969000\n",
      "3970000\n",
      "3971000\n",
      "3972000\n",
      "3973000\n",
      "3974000\n",
      "3975000\n",
      "3976000\n",
      "3977000\n",
      "3978000\n",
      "3979000\n",
      "3980000\n",
      "3981000\n",
      "3982000\n",
      "3983000\n",
      "3984000\n",
      "3985000\n",
      "3986000\n",
      "3987000\n",
      "3988000\n",
      "3989000\n",
      "3990000\n",
      "3991000\n",
      "3992000\n",
      "3993000\n",
      "3994000\n",
      "3995000\n",
      "3996000\n",
      "3997000\n",
      "3998000\n",
      "3999000\n",
      "4000000\n",
      "4001000\n",
      "4002000\n",
      "4003000\n",
      "4004000\n",
      "4005000\n",
      "4006000\n",
      "4007000\n",
      "4008000\n",
      "4009000\n",
      "4010000\n",
      "4011000\n",
      "4012000\n",
      "4013000\n",
      "4014000\n",
      "4015000\n",
      "4016000\n",
      "4017000\n",
      "4018000\n",
      "4019000\n",
      "4020000\n",
      "4021000\n",
      "4022000\n",
      "4023000\n",
      "4024000\n",
      "4025000\n",
      "4026000\n",
      "4027000\n",
      "4028000\n",
      "4029000\n",
      "4030000\n",
      "4031000\n",
      "4032000\n",
      "4033000\n",
      "4034000\n",
      "4035000\n",
      "4036000\n",
      "4037000\n",
      "4038000\n",
      "4039000\n",
      "4040000\n",
      "4041000\n",
      "4042000\n",
      "4043000\n",
      "4044000\n",
      "4045000\n",
      "4046000\n",
      "4047000\n",
      "4048000\n",
      "4049000\n",
      "4050000\n",
      "4051000\n",
      "4052000\n",
      "4053000\n",
      "4054000\n",
      "4055000\n",
      "4056000\n",
      "4057000\n",
      "4058000\n",
      "4059000\n",
      "4060000\n",
      "4061000\n",
      "4062000\n",
      "4063000\n",
      "4064000\n",
      "4065000\n",
      "4066000\n",
      "4067000\n",
      "4068000\n",
      "4069000\n",
      "4070000\n",
      "4071000\n",
      "4072000\n",
      "4073000\n",
      "4074000\n",
      "4075000\n",
      "4076000\n",
      "4077000\n",
      "4078000\n",
      "4079000\n",
      "4080000\n",
      "4081000\n",
      "4082000\n",
      "4083000\n",
      "4084000\n",
      "4085000\n",
      "4086000\n",
      "4087000\n",
      "4088000\n",
      "4089000\n",
      "4090000\n",
      "4091000\n",
      "4092000\n",
      "4093000\n",
      "4094000\n",
      "4095000\n",
      "4096000\n",
      "4097000\n",
      "4098000\n",
      "4099000\n",
      "4100000\n",
      "4101000\n",
      "4102000\n",
      "4103000\n",
      "4104000\n",
      "4105000\n",
      "4106000\n",
      "4107000\n",
      "4108000\n",
      "4109000\n",
      "4110000\n",
      "4111000\n",
      "4112000\n",
      "4113000\n",
      "4114000\n",
      "4115000\n",
      "4116000\n",
      "4117000\n",
      "4118000\n",
      "4119000\n",
      "4120000\n",
      "4121000\n",
      "4122000\n",
      "4123000\n",
      "4124000\n",
      "4125000\n",
      "4126000\n",
      "4127000\n",
      "4128000\n",
      "4129000\n",
      "4130000\n",
      "4131000\n",
      "4132000\n",
      "4133000\n",
      "4134000\n",
      "4135000\n",
      "4136000\n",
      "4137000\n",
      "4138000\n",
      "4139000\n",
      "4140000\n",
      "4141000\n",
      "4142000\n",
      "4143000\n",
      "4144000\n",
      "4145000\n",
      "4146000\n",
      "4147000\n",
      "4148000\n",
      "4149000\n",
      "4150000\n",
      "4151000\n",
      "4152000\n",
      "4153000\n",
      "4154000\n",
      "4155000\n",
      "4156000\n",
      "4157000\n",
      "4158000\n",
      "4159000\n",
      "4160000\n",
      "4161000\n",
      "4162000\n",
      "4163000\n",
      "4164000\n",
      "4165000\n",
      "4166000\n",
      "4167000\n",
      "4168000\n",
      "4169000\n",
      "4170000\n",
      "4171000\n",
      "4172000\n",
      "4173000\n",
      "4174000\n",
      "4175000\n",
      "4176000\n",
      "4177000\n",
      "4178000\n",
      "4179000\n",
      "4180000\n",
      "4181000\n",
      "4182000\n",
      "4183000\n",
      "4184000\n",
      "4185000\n",
      "4186000\n",
      "4187000\n",
      "4188000\n",
      "4189000\n",
      "4190000\n",
      "4191000\n",
      "4192000\n",
      "4193000\n",
      "4194000\n",
      "4195000\n",
      "4196000\n",
      "4197000\n",
      "4198000\n",
      "4199000\n",
      "4200000\n",
      "4201000\n",
      "4202000\n",
      "4203000\n",
      "4204000\n",
      "4205000\n",
      "4206000\n",
      "4207000\n",
      "4208000\n",
      "4209000\n",
      "4210000\n",
      "4211000\n",
      "4212000\n",
      "4213000\n",
      "4214000\n",
      "4215000\n",
      "4216000\n",
      "4217000\n",
      "4218000\n",
      "4219000\n",
      "4220000\n",
      "4221000\n",
      "4222000\n",
      "4223000\n",
      "4224000\n",
      "4225000\n",
      "4226000\n",
      "4227000\n",
      "4228000\n",
      "4229000\n",
      "4230000\n",
      "4231000\n",
      "4232000\n",
      "4233000\n",
      "4234000\n",
      "4235000\n",
      "4236000\n",
      "4237000\n",
      "4238000\n",
      "4239000\n",
      "4240000\n",
      "4241000\n",
      "4242000\n",
      "4243000\n",
      "4244000\n",
      "4245000\n",
      "4246000\n",
      "4247000\n",
      "4248000\n",
      "4249000\n",
      "4250000\n",
      "4251000\n",
      "4252000\n",
      "4253000\n",
      "4254000\n",
      "4255000\n",
      "4256000\n",
      "4257000\n",
      "4258000\n",
      "4259000\n",
      "4260000\n",
      "4261000\n",
      "4262000\n",
      "4263000\n",
      "4264000\n",
      "4265000\n",
      "4266000\n",
      "4267000\n",
      "4268000\n",
      "4269000\n",
      "4270000\n",
      "4271000\n",
      "4272000\n",
      "4273000\n",
      "4274000\n",
      "4275000\n",
      "4276000\n",
      "4277000\n",
      "4278000\n",
      "4279000\n",
      "4280000\n",
      "4281000\n",
      "4282000\n",
      "4283000\n",
      "4284000\n",
      "4285000\n",
      "4286000\n",
      "4287000\n",
      "4288000\n",
      "4289000\n",
      "4290000\n",
      "4291000\n",
      "4292000\n",
      "4293000\n",
      "4294000\n",
      "4295000\n",
      "4296000\n",
      "4297000\n",
      "4298000\n",
      "4299000\n",
      "4300000\n",
      "4301000\n",
      "4302000\n",
      "4303000\n",
      "4304000\n",
      "4305000\n",
      "4306000\n",
      "4307000\n",
      "4308000\n",
      "4309000\n",
      "4310000\n",
      "4311000\n",
      "4312000\n",
      "4313000\n",
      "4314000\n",
      "4315000\n",
      "4316000\n",
      "4317000\n",
      "4318000\n",
      "4319000\n",
      "4320000\n",
      "4321000\n",
      "4322000\n",
      "4323000\n",
      "4324000\n",
      "4325000\n",
      "4326000\n",
      "4327000\n",
      "4328000\n",
      "4329000\n",
      "4330000\n",
      "4331000\n",
      "4332000\n",
      "4333000\n",
      "4334000\n",
      "4335000\n",
      "4336000\n",
      "4337000\n",
      "4338000\n",
      "4339000\n",
      "4340000\n",
      "4341000\n",
      "4342000\n",
      "4343000\n",
      "4344000\n",
      "4345000\n",
      "4346000\n",
      "4347000\n",
      "4348000\n",
      "4349000\n",
      "4350000\n",
      "4351000\n",
      "4352000\n",
      "4353000\n",
      "4354000\n",
      "4355000\n",
      "4356000\n",
      "4357000\n",
      "4358000\n",
      "4359000\n",
      "4360000\n",
      "4361000\n",
      "4362000\n",
      "4363000\n",
      "4364000\n",
      "4365000\n",
      "4366000\n",
      "4367000\n",
      "4368000\n",
      "4369000\n",
      "4370000\n",
      "4371000\n",
      "4372000\n",
      "4373000\n",
      "4374000\n",
      "4375000\n",
      "4376000\n",
      "4377000\n",
      "4378000\n",
      "4379000\n",
      "4380000\n",
      "4381000\n",
      "4382000\n",
      "4383000\n",
      "4384000\n",
      "4385000\n",
      "4386000\n",
      "4387000\n",
      "4388000\n",
      "4389000\n",
      "4390000\n",
      "4391000\n",
      "4392000\n",
      "4393000\n",
      "4394000\n",
      "4395000\n",
      "4396000\n",
      "4397000\n",
      "4398000\n",
      "4399000\n",
      "4400000\n",
      "4401000\n",
      "4402000\n",
      "4403000\n",
      "4404000\n",
      "4405000\n",
      "4406000\n",
      "4407000\n",
      "4408000\n",
      "4409000\n",
      "4410000\n",
      "4411000\n",
      "4412000\n",
      "4413000\n",
      "4414000\n",
      "4415000\n",
      "4416000\n",
      "4417000\n",
      "4418000\n",
      "4419000\n",
      "4420000\n",
      "4421000\n",
      "4422000\n",
      "4423000\n",
      "4424000\n",
      "4425000\n",
      "4426000\n",
      "4427000\n",
      "4428000\n",
      "4429000\n",
      "4430000\n",
      "4431000\n",
      "4432000\n",
      "4433000\n",
      "4434000\n",
      "4435000\n",
      "4436000\n",
      "4437000\n",
      "4438000\n",
      "4439000\n",
      "4440000\n",
      "4441000\n",
      "4442000\n",
      "4443000\n",
      "4444000\n",
      "4445000\n",
      "4446000\n",
      "4447000\n",
      "4448000\n",
      "4449000\n",
      "4450000\n",
      "4451000\n",
      "4452000\n",
      "4453000\n",
      "4454000\n",
      "4455000\n",
      "4456000\n",
      "4457000\n",
      "4458000\n",
      "4459000\n",
      "4460000\n",
      "4461000\n",
      "4462000\n",
      "4463000\n",
      "4464000\n",
      "4465000\n",
      "4466000\n",
      "4467000\n",
      "4468000\n",
      "4469000\n",
      "4470000\n",
      "4471000\n",
      "4472000\n",
      "4473000\n",
      "4474000\n",
      "4475000\n",
      "4476000\n",
      "4477000\n",
      "4478000\n",
      "4479000\n",
      "4480000\n",
      "4481000\n",
      "4482000\n",
      "4483000\n",
      "4484000\n",
      "4485000\n",
      "4486000\n",
      "4487000\n",
      "4488000\n",
      "4489000\n",
      "4490000\n",
      "4491000\n",
      "4492000\n",
      "4493000\n",
      "4494000\n",
      "4495000\n",
      "4496000\n",
      "4497000\n",
      "4498000\n",
      "4499000\n",
      "4500000\n",
      "4501000\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_CN.shape[0]):\n",
    "    if i%1000 == 0 :\n",
    "        print(i)\n",
    "    ' '.join(df_CN['CN'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"dasan_bert.bin\", \"wb\" ) as file:\n",
    "    pickle.dump(df_CN, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CN['CN'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_naver_movie.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "24c7c4de897842daabfb4ab5bce59a5f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "283290212a5c48a087e649cb015d65e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_954cca3cf9f04ca8bbc7337f0301e04a",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afb83fc933ed4efd946df40e7044ef75",
      "value": 995526
     }
    },
    "2b925cf0822f4bbfae8bd4b6d9ea3559": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fe822a741884e408b7b098bdd520391",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_931bdaf9d81f4c5c96be6a591f5d3a8a",
      "value": 714314041
     }
    },
    "36bf4fd94daa477cb304f6e2f0e59585": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3706a29c1fd14cafb1527ba850d24dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc40527794924690a1a50ee4a5683731",
      "placeholder": "​",
      "style": "IPY_MODEL_b199891e7d7649d68480454645be2b8e",
      "value": "100% 521/521 [00:00&lt;00:00, 7.98kB/s]"
     }
    },
    "3fa7bd6d2ebf435ca630fef08fe0e9a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "47e09c7e47554a92939c6d6cdaff9f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c72b798f32c446b3b6cad9a12679b3ec",
      "placeholder": "​",
      "style": "IPY_MODEL_9f5bd34100b14dd28cc3dd45eac9ee96",
      "value": "100% 996k/996k [00:00&lt;00:00, 2.62MB/s]"
     }
    },
    "50a457e2365d4d8f9b5cab009198b1c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc31bfb1dcfd4f0fba7dbcd02dab6671",
      "placeholder": "​",
      "style": "IPY_MODEL_cc539678cb0f474385c29d29fec3aee4",
      "value": "100% 714M/714M [00:19&lt;00:00, 36.5MB/s]"
     }
    },
    "566d90a8747a41069a8a3e8809fcf1c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8a0fa47220f426d877ca05540befdfe",
      "max": 521,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3fa7bd6d2ebf435ca630fef08fe0e9a1",
      "value": 521
     }
    },
    "7be0183b68c140f993db6df970e1b59e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fe822a741884e408b7b098bdd520391": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "931bdaf9d81f4c5c96be6a591f5d3a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "954cca3cf9f04ca8bbc7337f0301e04a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f5bd34100b14dd28cc3dd45eac9ee96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afb83fc933ed4efd946df40e7044ef75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b199891e7d7649d68480454645be2b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8a0fa47220f426d877ca05540befdfe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba3543867b3949b98a56b79766a7fe39": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_566d90a8747a41069a8a3e8809fcf1c7",
       "IPY_MODEL_3706a29c1fd14cafb1527ba850d24dda"
      ],
      "layout": "IPY_MODEL_7be0183b68c140f993db6df970e1b59e"
     }
    },
    "c33742ffe86a43baaf623f55386f6b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_283290212a5c48a087e649cb015d65e2",
       "IPY_MODEL_47e09c7e47554a92939c6d6cdaff9f4d"
      ],
      "layout": "IPY_MODEL_24c7c4de897842daabfb4ab5bce59a5f"
     }
    },
    "c72b798f32c446b3b6cad9a12679b3ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc31bfb1dcfd4f0fba7dbcd02dab6671": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc539678cb0f474385c29d29fec3aee4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d86637397e3f4c259bf6aff32a8ac917": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b925cf0822f4bbfae8bd4b6d9ea3559",
       "IPY_MODEL_50a457e2365d4d8f9b5cab009198b1c1"
      ],
      "layout": "IPY_MODEL_36bf4fd94daa477cb304f6e2f0e59585"
     }
    },
    "dc40527794924690a1a50ee4a5683731": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
